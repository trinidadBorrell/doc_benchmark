#!/usr/bin/env python3
"""
Pipeline to benchmark data

A comprehensive Python pipeline for processing EEG data through three main phases:
1. Markers: Compute EEG markers and features from raw data
2. Analysis: Compare markers and perform individual subject analysis
3. Models: Train extra trees for binary classification (VS vs MCS) 


Usage:
    python pipeline.py --subject AD023 --metadata-dir /path/to/metadata --data-dir /path/to/fifdata                 # Process one subject
    python pipeline.py --subjects AD023,YC260 --metadata-dir /path/to/metadata --data-dir /path/to/fifdata             # Process specific subjects  
    python pipeline.py --all --metadata-dir /path/to/metadata --data-dir /path/to/fifdata                              # Process all subjects
    python pipeline.py --random 5 --metadata-dir /path/to/metadata --data-dir /path/to/fifdata                         # Process 5 random subjects
    python pipeline.py --subject AD023 --skip-models --metadata-dir /path/to/metadata --data-dir /path/to/fifdata      # Skip model training
    python pipeline.py --all --markers-only --metadata-dir /path/to/metadata --data-dir /path/to/fifdata               # Only compute markers
    python pipeline.py --analysis-only --metadata-dir /path/to/metadata --data-dir /path/to/fifdata                    # Only run analysis on existing results

    python pipeline.py --subject AD023 --metadata-dir /Users/trinidad.borrell/Documents/Work/PhD/Proyects/nice/doc_a_data/metadata --data-dir /Users/trinidad.borrell/Documents/Work/PhD/data/TOTEM/zero_shot_data/fifdata/fifdata
Authors: Trinidad Borrell <trinidad.borrell@gmail.com>
"""

import argparse
import sys
import subprocess
import logging
import random
from pathlib import Path
from datetime import datetime
from typing import List, Tuple, Optional
from concurrent.futures import ProcessPoolExecutor, as_completed
import multiprocessing


class Pipeline:
    """Main pipeline class for benchmark data analysis."""
    
    def __init__(self, 
                 data_dir: str,
                 results_dir: str,
                 src_dir: str,
                 metadata_dir: str,
                 batch_size: int = 1,
                 verbose: bool = False,
                 dry_run: bool = False,
                 skip_smi: bool = False,
                 skip_gfp: bool = False):
        """
        Initialize the pipeline.
        
        Parameters
        ----------
        data_dir : str
            Path to the raw data directory
        results_dir : str
            Path to save results
        src_dir : str
            Path to the source code directory
        metadata_dir : str
            Path to metadata directory
        batch_size : int
            Number of parallel processes
        verbose : bool
            Enable verbose logging
        dry_run : bool
            Show what would be done without executing
        skip_smi : bool
            Skip SymbolicMutualInformation computation (recommended for large datasets)
        skip_gfp : bool
            Skip Global Field Power analysis (speeds up global analysis)
        """
        self.data_dir = Path(data_dir)
        self.results_dir = Path(results_dir)
        self.src_dir = Path(src_dir)
        self.metadata_dir = Path(metadata_dir)
        
        # Determine optimal batch size
        max_workers = max(1, multiprocessing.cpu_count() - 1)
        self.batch_size = min(batch_size, max_workers)
        
        self.verbose = verbose
        self.dry_run = dry_run
        self.skip_smi = skip_smi
        self.skip_gfp = skip_gfp
        
        # Setup logging (must come before using self.logger)
        self._setup_logging()
        
        # Log parallelization info
        if self.batch_size > 1:
            self.logger.info(f"ðŸš€ Parallel processing enabled: {self.batch_size} workers (CPU cores: {multiprocessing.cpu_count()})")
        else:
            self.logger.info(f"âš™ï¸  Sequential processing (use --batch-size N for parallel processing)")
        
        # Validate directories
        self._validate_directories()
        
        # Track progress
        self.completed_subjects = []
        self.failed_subjects = []
        
    def _setup_logging(self):
        """Setup logging configuration."""
        log_dir = self.results_dir / "logs"
        log_dir.mkdir(parents=True, exist_ok=True)
        
        log_file = log_dir / f"pipeline_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        
        # Configure logging
        log_level = logging.DEBUG if self.verbose else logging.INFO
        logging.basicConfig(
            level=log_level,
            format='[%(asctime)s] %(levelname)s: %(message)s',
            datefmt='%H:%M:%S',
            handlers=[
                logging.FileHandler(log_file),
                logging.StreamHandler(sys.stdout)
            ]
        )
        
        self.logger = logging.getLogger(__name__)
        self.logger.info(f"Pipeline log file: {log_file}")
        
    def _validate_directories(self):
        """Validate that required directories exist."""
        if not self.data_dir.exists():
            raise FileNotFoundError(f"Data directory not found: {self.data_dir}")
            
        if not self.src_dir.exists():
            raise FileNotFoundError(f"Source directory not found: {self.src_dir}")
            
        # Create results directory if it doesn't exist
        self.results_dir.mkdir(parents=True, exist_ok=True)
        
        # Check for required source files
        required_files = [
            "markers/compute_doc_forest_markers_variable.py",
            "markers/compute_doc_forest_features_variable.py",
            "model/extratrees.py",
            "analysis/individual_analysis.py",
            "analysis/global_analysis.py",
            "analysis/statistical_analysis.py",
            "decoder/decoder.py"
        ]
        
        missing_files = []
        for file_path in required_files:
            if not (self.src_dir / file_path).exists():
                missing_files.append(file_path)
                
        if missing_files:
            raise FileNotFoundError(f"Missing required source files: {missing_files}")
    
    def is_subject_complete(self, subject_id: str, session: str) -> bool:
        """
        Check if a subject/session is already complete based on required files and folders.
        
        A subject is considered complete if all four .npy feature files exist.
        The .hdf5 marker files and analysis files are optional for completeness check,
        as the features are what's needed for downstream model training.
        
        Parameters
        ----------
        subject_id : str
            Subject identifier
        session : str
            Session identifier
            
        Returns
        -------
        bool
            True if subject/session is complete, False otherwise
        """
        results_dir = self.results_dir / "SUBJECTS" / f"sub-{subject_id}" / session
        
        # Check if the main result directory exists
        if not results_dir.exists():
            return False
        
        # Check features_variable folder and required .npy files
        # This is the PRIMARY requirement - if all features exist, subject is complete
        features_dir = results_dir / "features_variable"
        required_npy_files = [
            'scalars_reconstructed.npy',
            'topos_reconstructed.npy', 
            'topos_original.npy',
            'scalars_original.npy'
        ]
        
        if not features_dir.exists():
            return False
            
        for npy_file in required_npy_files:
            if not (features_dir / npy_file).exists():
                return False
        
        # If all feature files exist, the subject is considered complete
        # We don't require .hdf5 marker files or analysis files to exist
        # This allows users to delete intermediate .hdf5 files to save space
        return True

    def is_decoder_subject_complete(self, subject_id: str, session: str, decoder_output_dir: Path) -> bool:
        """
        Check if decoder results already exist for a subject/session.
        
        Parameters
        ----------
        subject_id : str
            Subject identifier
        session : str
            Session identifier
        decoder_output_dir : Path
            Decoder output directory to check
            
        Returns
        -------
        bool
            True if decoder results exist, False otherwise
        """
        sub_ses_dir = decoder_output_dir / f"sub-{subject_id}" / f"ses-{session}"
        
        # Check for required decoder files
        required_files = [
            sub_ses_dir / "data" / "decoding_results.pkl",
            sub_ses_dir / "data" / "decoding_summary.json", 
            sub_ses_dir / "data" / "times.npy"
        ]
        
        return all(f.exists() for f in required_files)
        
    def find_best_decoder_results_directory(self) -> Tuple[Path, dict]:
        """
        Find the best decoder results directory (one with most completed subjects).
        
        Returns
        -------
        Tuple[Path, dict]
            Path to best decoder directory and dict with completion stats per directory
        """
        decoder_base_dir = self.results_dir / "DECODER"
        if not decoder_base_dir.exists():
            return None, {}
            
        # Find all decoder_results_* directories
        decoder_dirs = list(decoder_base_dir.glob("decoder_results_*"))
        if not decoder_dirs:
            return None, {}
        
        # Get all subjects that could potentially be processed
        subjects_with_data = self.discover_subjects(force_recompute=True)
        
        # Check completion status for each directory
        directory_stats = {}
        for decoder_dir in decoder_dirs:
            completed_count = 0
            completed_subjects = []
            
            for subject_id, session in subjects_with_data:
                if self.is_decoder_subject_complete(subject_id, session, decoder_dir):
                    completed_count += 1
                    completed_subjects.append((subject_id, session))
            
            directory_stats[decoder_dir] = {
                'completed_count': completed_count,
                'completed_subjects': completed_subjects,
                'total_possible': len(subjects_with_data)
            }
        
        # Find directory with most completed subjects
        if not directory_stats:
            return None, {}
        
        best_dir = max(directory_stats.keys(), key=lambda d: directory_stats[d]['completed_count'])
        return best_dir, directory_stats

    def discover_subjects(self, force_recompute: bool = False) -> List[Tuple[str, str]]:
        """
        Discover all subjects with available sessions.
        
        Parameters
        ----------
        force_recompute : bool
            If True, include subjects even if they are already complete
            
        Returns
        -------
        List[Tuple[str, str]]
            List of (subject_id, session) tuples
        """
        subjects = []
        skipped_complete = []
        
        for subject_dir in self.data_dir.glob("sub-*"):
            if not subject_dir.is_dir():
                continue
                
            subject_id = subject_dir.name.replace("sub-", "")
            
            # Find all sessions for this subject
            for session_dir in subject_dir.glob("ses-*"):
                if not session_dir.is_dir():
                    continue
                    
                session = session_dir.name
                
                # Check if both original and reconstructed files exist
                original_files = list(session_dir.glob("*_original.fif"))
                recon_files = list(session_dir.glob("*_recon.fif"))
                
                if original_files and recon_files:
                    # Check if subject is already complete
                    if not force_recompute and self.is_subject_complete(subject_id, session):
                        skipped_complete.append((subject_id, session))
                        self.logger.info(f"â­ï¸  Skipping {subject_id}/{session} - already complete")
                    else:
                        subjects.append((subject_id, session))
        
        if skipped_complete:
            self.logger.info(f"ðŸ“‹ Skipped {len(skipped_complete)} already completed subjects")
            if self.verbose:
                for subject_id, session in skipped_complete:
                    self.logger.debug(f"   - {subject_id}/{session}")
                    
        return subjects
    
    def resolve_subjects(self, subject_args: List[str], force_recompute: bool = False) -> List[Tuple[str, str]]:
        """
        Resolve subject selection arguments to actual subject/session pairs.
        
        Parameters
        ----------
        subject_args : List[str]
            Subject selection arguments
        force_recompute : bool
            If True, include subjects even if they are already complete
            
        Returns
        -------
        List[Tuple[str, str]]
            List of (subject_id, session) tuples
        """
        all_subjects = self.discover_subjects(force_recompute=force_recompute)
        
        if not all_subjects:
            raise ValueError("No subjects found in data directory")
            
        resolved = []
        
        for arg in subject_args:
            if arg == "ALL":
                resolved.extend(all_subjects)
            elif arg.startswith("RANDOM:"):
                count = int(arg.split(":")[1])
                shuffled = random.sample(all_subjects, min(count, len(all_subjects)))
                resolved.extend(shuffled)
            else:
                # Handle specific subject ID
                matching = [(s, ses) for s, ses in all_subjects if s == arg]
                if not matching:
                    self.logger.warning(f"No sessions found for subject {arg}")
                else:
                    resolved.extend(matching)
        
        # Remove duplicates and sort
        resolved = list(set(resolved))
        resolved.sort()
        
        return resolved
    
    def run_markers_phase(self, subject_id: str, session: str) -> bool:
        """
        Run the markers computation phase for a subject/session.
        
        Parameters
        ----------
        subject_id : str
            Subject identifier
        session : str
            Session identifier
            
        Returns
        -------
        bool
            True if successful, False otherwise
        """
        try:
            subject_dir = self.data_dir / f"sub-{subject_id}" / session
            results_dir = self.results_dir / "SUBJECTS" / f"sub-{subject_id}" / session
            
            # Create output directories
            markers_dir = results_dir / "markers_variable"
            features_dir = results_dir / "features_variable"
            markers_dir.mkdir(parents=True, exist_ok=True)
            features_dir.mkdir(parents=True, exist_ok=True)
            
            # Find data files
            original_file = next(subject_dir.glob("*_original.fif"), None)
            recon_file = next(subject_dir.glob("*_recon.fif"), None)
            
            if not original_file or not recon_file:
                self.logger.error(f"Missing data files for {subject_id}/{session}")
                return False
                
            self.logger.info(f"Computing markers for {subject_id}/{session}")
            
            # Process original data
            self.logger.info(f"  Step 1: Computing markers from {original_file.name}")
            cmd = [
                "python", str(self.src_dir / "markers/compute_doc_forest_markers_variable.py"),
                str(original_file),
                "--output", str(markers_dir / "markers_original.hdf5"),
                "--plot"
            ]
            if self.skip_smi:
                cmd.append("--skip-smi")
            if not self._run_command(cmd):
                return False
                
            self.logger.info("  Step 2: Computing features from markers_original.hdf5")
            if not self._run_command([
                "python", str(self.src_dir / "markers/compute_doc_forest_features_variable.py"),
                str(markers_dir / "markers_original.hdf5"),
                "--output-scalars", str(features_dir / "scalars_original.npy"),
                "--output-topos", str(features_dir / "topos_original.npy")
            ]):
                return False
            
            # Process reconstructed data
            self.logger.info(f"  Step 3: Computing markers from {recon_file.name}")
            cmd = [
                "python", str(self.src_dir / "markers/compute_doc_forest_markers_variable.py"),
                str(recon_file),
                "--output", str(markers_dir / "markers_reconstructed.hdf5"),
                "--plot"
            ]
            if self.skip_smi:
                cmd.append("--skip-smi")
            if not self._run_command(cmd):
                return False
                
            self.logger.info("  Step 4: Computing features from markers_reconstructed.hdf5")
            if not self._run_command([
                "python", str(self.src_dir / "markers/compute_doc_forest_features_variable.py"),
                str(markers_dir / "markers_reconstructed.hdf5"),
                "--output-scalars", str(features_dir / "scalars_reconstructed.npy"),
                "--output-topos", str(features_dir / "topos_reconstructed.npy")
            ]):
                return False
            
            self.logger.info(f"âœ“ Markers completed for {subject_id}/{session}")
            return True
            
        except Exception as e:
            self.logger.error(f"âœ— Markers failed for {subject_id}/{session}: {e}")
            return False
    
    def run_models_phase(self) -> bool:
        """
        Run the model training phase across all processed subjects.
        This should be called after all subjects have completed markers and analysis phases.
        
        Returns
        -------
        bool
            True if successful, False otherwise
        """
        try:
            self.logger.info("Running global models training")
            
            # First check if we have enough successful subjects
            subjects_dir = self.results_dir / "SUBJECTS"
            if not subjects_dir.exists():
                self.logger.error("No subjects directory found")
                return False
                
            # Count subjects with complete data
            complete_subjects = []
            for subject_dir in subjects_dir.glob("sub-*"):
                if not subject_dir.is_dir():
                    continue
                for session_dir in subject_dir.glob("ses-*"):
                    if not session_dir.is_dir():
                        continue
                    features_dir = session_dir / "features_variable"
                    if (features_dir.exists() and 
                        (features_dir / "scalars_original.npy").exists() and
                        (features_dir / "scalars_reconstructed.npy").exists()):
                        complete_subjects.append(f"{subject_dir.name}/{session_dir.name}")
            
            self.logger.info(f"Found {len(complete_subjects)} subjects with complete data")
            if len(complete_subjects) < 2:
                self.logger.error("Need at least 2 subjects with complete data for model training")
                return False
            
            # Create global models output directory
            models_output_dir = self.results_dir / "EXTRATREES" / f"models_{datetime.now().strftime('%Y-%m-%d_%H%M%S')}"
            models_output_dir.mkdir(parents=True, exist_ok=True)
            
            # Get patient labels path from metadata directory
            patient_labels_path = self.metadata_dir / "patient_labels_with_controls.csv"
            
            if not patient_labels_path.exists():
                self.logger.error(f"Patient labels file not found at: {patient_labels_path}")
                self.logger.error(f"Please check that the file exists and the --metadata-dir path is correct")
                self.logger.info(f"Looking for: patient_labels_with_controls.csv")
                self.logger.info(f"In directory: {self.metadata_dir}")
                return False
            
            self.logger.info(f"Using patient labels: {patient_labels_path}")
            
            # Train cross-data models for different marker types
            marker_types = ["scalar", "topo"]
            
            success = True
            for marker_type in marker_types:
                self.logger.info(f"Training cross-data {marker_type} models...")
                self.logger.info("=" * 70)
                self.logger.info("CROSS-DATA CLASSIFICATION APPROACH:")
                self.logger.info("  This approach ensures NO SUBJECT BIAS and NO DATA LEAKAGE:")
                self.logger.info("  1. Uses SAME train/test subject splits for both original and reconstructed")
                self.logger.info("  2. Trains Model A on ORIGINAL data")
                self.logger.info("  3. Trains Model B on RECONSTRUCTED data")
                self.logger.info("  4. Tests BOTH models on BOTH test sets (original & reconstructed)")
                self.logger.info("  5. All 4 test scenarios use the SAME test subjects")
                self.logger.info("=" * 70)
                
                config_output_dir = models_output_dir / f"{marker_type}"
                
                # Use the new cross-data classification which trains both models and tests on both test sets
                # CRITICAL: The --cross-data flag enables proper cross-testing with consistent subjects
                if not self._run_command([
                    "python", str(self.src_dir / "model/extratrees.py"),
                    "--data-dir", str(self.results_dir / "SUBJECTS"),
                    "--patient-labels", str(patient_labels_path),
                    "--output-dir", str(config_output_dir),
                    "--marker-type", marker_type,
                    "--cross-data"  # CRITICAL: Enables CrossDataClassifier for proper cross-testing
                ]):
                    self.logger.error(f"Failed to train cross-data {marker_type} models")
                    success = False
                else:
                    self.logger.info(f"âœ“ Cross-data {marker_type} models completed")
                    self.logger.info(f"   Results saved with 4 test scenarios:")
                    self.logger.info(f"   - Model A (original) â†’ Original test subjects")
                    self.logger.info(f"   - Model A (original) â†’ Reconstructed test subjects")
                    self.logger.info(f"   - Model B (reconstructed) â†’ Original test subjects")
                    self.logger.info(f"   - Model B (reconstructed) â†’ Reconstructed test subjects")
            
            if success:
                self.logger.info("âœ“ Global models training completed")
            else:
                self.logger.error("âœ— Some models failed to train")
                
            return success
            
        except Exception as e:
            self.logger.error(f"âœ— Global models training failed: {e}")
            return False
    
    def run_analysis_phase(self, subject_id: str, session: str) -> bool:
        """
        Run the analysis phase for a subject/session.
        
        Parameters
        ----------
        subject_id : str
            Subject identifier
        session : str
            Session identifier
            
        Returns
        -------
        bool
            True if successful, False otherwise
        """
        try:
            results_dir = self.results_dir / "SUBJECTS" / f"sub-{subject_id}" / session 
            analysis_dir = results_dir / "individual_analysis"
            analysis_dir.mkdir(parents=True, exist_ok=True)
            
            # Check if required feature files exist
            features_dir = results_dir / "features_variable"
            required_files = [
                features_dir / "scalars_original.npy",
                features_dir / "scalars_reconstructed.npy",
                features_dir / "topos_original.npy",
                features_dir / "topos_reconstructed.npy"
            ]
            
            missing_files = [f for f in required_files if not f.exists()]
            if missing_files:
                self.logger.warning(f"Missing feature files for {subject_id}/{session}: {[f.name for f in missing_files]}")
                self.logger.warning(f"Skipping analysis for {subject_id}/{session}")
                return False
            
            self.logger.info(f"Running analysis for {subject_id}/{session}")
            
            # Get the fif data directory for GFP analysis
            fif_data_dir = self.data_dir / f"sub-{subject_id}" / session
            
            # Run individual analysis (replaces compare_markers.py)
            if not self._run_command([
                "python", str(self.src_dir / "analysis/individual_analysis.py"),
                str(results_dir),
                str(fif_data_dir),
                "--output", str(analysis_dir)
            ]):
                return False
            
            self.logger.info(f"âœ“ Analysis completed for {subject_id}/{session}")
            return True
            
        except Exception as e:
            self.logger.error(f"âœ— Analysis failed for {subject_id}/{session}: {e}")
            return False
    
    def run_decoder_phase(self, force_recompute: bool = False, aggregate_only: bool = False) -> bool:
        """
        Run decoder phase across all processed subjects.
        This decodes original vs reconstructed EEG data.
        
        Parameters
        ----------
        force_recompute : bool
            If True, recompute all subjects even if they already exist
        aggregate_only : bool
            If True, only aggregate existing results without processing subjects
        
        Returns
        -------
        bool
            True if successful, False otherwise
        """
        try:
            self.logger.info("Running decoder analysis")
            
            # Check for existing decoder results across ALL directories
            best_decoder_dir, directory_stats = self.find_best_decoder_results_directory()
            decoder_output_dir = None
            
            if best_decoder_dir and not force_recompute:
                # Display summary of all decoder directories
                self.logger.info("ðŸ“Š Decoder directories found:")
                for decoder_dir, stats in directory_stats.items():
                    completion_pct = (stats['completed_count'] / stats['total_possible']) * 100 if stats['total_possible'] > 0 else 0
                    status = "âœ… BEST" if decoder_dir == best_decoder_dir else "ðŸ“"
                    self.logger.info(f"   {status} {decoder_dir.name}: {stats['completed_count']}/{stats['total_possible']} subjects ({completion_pct:.1f}%)")
                
                # Get stats for best directory
                best_stats = directory_stats[best_decoder_dir]
                completed_subjects = best_stats['completed_subjects']
                subjects_with_data = self.discover_subjects(force_recompute=True)
                pending_subjects = [s for s in subjects_with_data if s not in completed_subjects]
                
                self.logger.info(f"ðŸŽ¯ Using best directory: {best_decoder_dir}")
                self.logger.info(f"ðŸ“ˆ Status: {len(completed_subjects)} completed, {len(pending_subjects)} pending")
                
                if pending_subjects:
                    # Use best existing directory 
                    decoder_output_dir = best_decoder_dir
                    self.logger.info(f"ðŸ”„ Resuming decoder analysis in existing directory")
                    self.logger.info(f"ðŸ“‹ Pending subjects: {[f'{s}/{ses}' for s, ses in pending_subjects[:5]]}{'...' if len(pending_subjects) > 5 else ''}")
                else:
                    self.logger.info("âœ… All subjects already processed - skipping decoder analysis")
                    return True
            else:
                if force_recompute:
                    self.logger.info("ðŸ”„ Force recompute enabled - will create new directory")
                else:
                    self.logger.info("ðŸ“ No existing decoder directories found - will create new directory")
            
            if decoder_output_dir is None:
                # Create new decoder output directory
                decoder_output_dir = self.results_dir / "DECODER" / f"decoder_results_{datetime.now().strftime('%Y-%m-%d_%H%M%S')}"
                decoder_output_dir.mkdir(parents=True, exist_ok=True)
                self.logger.info(f"ðŸ†• Created new decoder output directory: {decoder_output_dir}")
            
            self.logger.info(f"ðŸŽ¯ Final decoder directory: {decoder_output_dir}")
            
            # Build decoder command
            cmd = [
                "python", str(self.src_dir / "decoder/decoder.py"),
                "--main_path", str(self.data_dir),
                "--output_dir", str(decoder_output_dir),
                "--cv", "3",
                "--n_jobs", "1",  # Avoid memory multiplication from parallelization
                "--verbose"
            ]
            
            # Add patient labels for subject-type aggregation
            patient_labels_path = self.metadata_dir / "patient_labels_with_controls.csv"
            if patient_labels_path.exists():
                cmd.extend(["--patient-labels", str(patient_labels_path)])
                self.logger.info(f"ðŸ“Š Using patient labels for subject-type aggregation: {patient_labels_path}")
            
            # Add aggregate-only flag if requested
            if aggregate_only:
                cmd.append("--aggregate-only")
                self.logger.info("ðŸ”„ Aggregate-only mode: will only aggregate existing results")
            
            # Run decoder on all available subjects for robust population-level analysis
            # Memory optimization: decoder now uses float32 and n_jobs=1
            # The decoder script itself will skip subjects that are already complete
            if not self._run_command(cmd):
                return False
            
            self.logger.info("âœ“ Decoder analysis completed")
            return True
            
        except Exception as e:
            self.logger.error(f"âœ— Decoder analysis failed: {e}")
            return False
    
    def run_global_analysis(self) -> bool:
        """
        Run global analysis across all processed subjects.
        
        Returns
        -------
        bool
            True if successful, False otherwise
        """
        try:
            self.logger.info("Running global analysis")
            
            patient_labels_path = self.metadata_dir / "patient_labels_with_controls.csv"
            
            if not patient_labels_path.exists():
                self.logger.error(f"Patient labels file not found at: {patient_labels_path}")
                self.logger.error(f"Please check that the file exists and the --metadata-dir path is correct")
                return False
            
            global_output_dir = self.results_dir / "GLOBAL" / f"global_results_{datetime.now().strftime('%Y-%m-%d_%H%M%S')}"
            global_output_dir.mkdir(parents=True, exist_ok=True)
            results_dir = self.results_dir / "SUBJECTS"
            
            # Build command with optional skip-gfp parameter
            cmd = [
                "python", str(self.src_dir / "analysis/global_analysis.py"),
                "--results-dir", str(results_dir),
                "--output-dir", str(global_output_dir),
                "--patient-labels", str(patient_labels_path),
                "--data-dir", str(self.data_dir)
            ]
            
            if self.skip_gfp:
                cmd.append("--skip-gfp")
                self.logger.info("ðŸš« Skip GFP option enabled for global analysis")
            
            if not self._run_command(cmd):
                return False
            
            self.logger.info("âœ“ Global analysis completed")
            return True
            
        except Exception as e:
            self.logger.error(f"âœ— Global analysis failed: {e}")
            return False
    
    def run_statistical_analysis(self) -> bool:
        """
        Run statistical analysis across all processed subjects.
        
        Returns
        -------
        bool
            True if successful, False otherwise
        """
        try:
            self.logger.info("Running statistical analysis")
            
            patient_labels_path = self.metadata_dir / "patient_labels_with_controls.csv"
            
            if not patient_labels_path.exists():
                self.logger.error(f"Patient labels file not found at: {patient_labels_path}")
                self.logger.error(f"Please check that the file exists and the --metadata-dir path is correct")
                return False
            
            stats_output_dir = self.results_dir / "STATISTICS" / f"statistics_results_{datetime.now().strftime('%Y-%m-%d_%H%M%S')}"
            stats_output_dir.mkdir(parents=True, exist_ok=True)
            results_dir = self.results_dir / "SUBJECTS"
            
            if not self._run_command([
                "python", str(self.src_dir / "analysis/statistical_analysis.py"),
                "--results-dir", str(results_dir),
                "--output-dir", str(stats_output_dir),
                "--patient-labels", str(patient_labels_path)
            ]):
                return False
            
            self.logger.info("âœ“ Statistical analysis completed")
            return True
            
        except Exception as e:
            self.logger.error(f"âœ— Statistical analysis failed: {e}")
            return False
    
    def process_subject(self, subject_id: str, session: str, 
                       skip_markers: bool = False,
                       skip_models: bool = False, 
                       skip_analysis: bool = False) -> bool:
        """
        Process a single subject through individual phases (markers and analysis).
        
        Parameters
        ----------
        subject_id : str
            Subject identifier
        session : str
            Session identifier
        skip_markers : bool
            Skip markers computation phase
        skip_models : bool
            Skip models training phase 
        skip_analysis : bool
            Skip analysis phase
            
        Returns
        -------
        bool
            True if all requested phases completed successfully
        """
        self.logger.info(f"Processing {subject_id}/{session}")
        
        success = True
        
        # Phase 1: Markers
        if not skip_markers:
            if not self.run_markers_phase(subject_id, session):
                success = False
        else:
            self.logger.info(f"Skipping markers for {subject_id}/{session}")
        
        # Phase 2: Analysis  
        if not skip_analysis and success:
            if not self.run_analysis_phase(subject_id, session):
                success = False
        else:
            if skip_analysis:
                self.logger.info(f"Skipping analysis for {subject_id}/{session}")
        
        # Don't modify instance variables here - will be handled by caller
        # This is important for parallel processing
        if success:
            self.logger.info(f"âœ“ Completed {subject_id}/{session}")
        else:
            self.logger.error(f"âœ— Failed {subject_id}/{session}")
            
        return success
    
    def run_pipeline(self, subjects: List[Tuple[str, str]],
                    skip_markers: bool = False,
                    skip_models: bool = False,
                    skip_analysis: bool = False,
                    skip_decoder: bool = False,
                    skip_global: bool = False,
                    skip_statistics: bool = False,
                    force_recompute: bool = False) -> dict:
        """
        Run the complete pipeline for multiple subjects.
        
        Pipeline order:
        1. Individual subject processing (markers + analysis)
        2. Decoder analysis
        3. Global analysis
        4. Statistical analysis
        5. Model training

        Parameters
        ----------
        subjects : List[Tuple[str, str]]
            List of (subject_id, session) tuples to process
        skip_markers : bool
            Skip markers computation phase
        skip_models : bool
            Skip global models training phase
        skip_analysis : bool
            Skip individual analysis phase
        skip_decoder : bool
            Skip decoder analysis phase
        skip_global : bool
            Skip global analysis phase
        skip_statistics : bool
            Skip statistical analysis phase
        force_recompute : bool
            Force recomputation of all phases, including decoder
            
        Returns
        -------
        dict
            Summary of pipeline execution
        """
        start_time = datetime.now()
        
        self.logger.info("=" * 60)
        self.logger.info("PIPELINE START")
        self.logger.info("=" * 60)
        self.logger.info(f"Start time: {start_time}")
        self.logger.info(f"Subjects to process: {len(subjects)}")
        self.logger.info(f"Parallel processes: {self.batch_size}")
        
        if self.dry_run:
            self.logger.info("DRY RUN MODE - No actual processing")
            return {"status": "dry_run", "subjects": subjects}
        
        # Phase 1: Process subjects
        if self.batch_size > 1:
            self._run_parallel(subjects, skip_markers, skip_models, skip_analysis)
        else:
            self._run_sequential(subjects, skip_markers, skip_models, skip_analysis)

        # Phase 2: Decoder Analysis
        if not skip_decoder and self.completed_subjects:
            self.logger.info("Starting decoder analysis phase...")
            decoder_success = self.run_decoder_phase(force_recompute=force_recompute)
            if not decoder_success:
                self.logger.error("Decoder analysis failed")

        # Phase 3: Global Analysis  
        if not skip_global and self.completed_subjects:
            self.run_global_analysis()
        
        # Phase 4: Statistical Analysis (after global) - only run if global analysis was skipped
        if not skip_statistics and self.completed_subjects and skip_global:
            self.logger.info("Starting standalone statistical analysis phase...")
            stats_success = self.run_statistical_analysis()
            if not stats_success:
                self.logger.error("Statistical analysis failed")
        elif not skip_statistics and not skip_global:
            self.logger.info("âœ“ Statistical analysis was included in global analysis")
        
        # Phase 5: Models Training (run even if some subjects failed, as long as we have enough data)
        if not skip_models:
            self.logger.info("Starting global models training phase...")
            models_success = self.run_models_phase()
            if not models_success:
                self.logger.error("Global models training failed")
        
        # Summary
        end_time = datetime.now()
        duration = end_time - start_time
        
        self.logger.info("=" * 60)
        self.logger.info("PIPELINE COMPLETE")
        self.logger.info("=" * 60)
        self.logger.info(f"End time: {end_time}")
        self.logger.info(f"Duration: {duration}")
        self.logger.info(f"Completed: {len(self.completed_subjects)}")
        self.logger.info(f"Failed: {len(self.failed_subjects)}")
        
        if self.failed_subjects:
            self.logger.error(f"Failed subjects: {self.failed_subjects}")
        
        return {
            "status": "complete",
            "start_time": start_time,
            "end_time": end_time,
            "duration": duration,
            "completed": self.completed_subjects,
            "failed": self.failed_subjects
        }
    
    def _run_parallel(self, subjects: List[Tuple[str, str]],
                     skip_markers: bool, skip_models: bool, skip_analysis: bool):
        """Run processing in parallel."""
        self.logger.info(f"Running parallel processing with {self.batch_size} processes")
        
        with ProcessPoolExecutor(max_workers=self.batch_size) as executor:
            # Submit all jobs
            future_to_subject = {
                executor.submit(self.process_subject, subj_id, session, 
                              skip_markers, skip_models, skip_analysis): (subj_id, session)
                for subj_id, session in subjects
            }
            
            # Collect results
            for future in as_completed(future_to_subject):
                subject_id, session = future_to_subject[future]
                try:
                    success = future.result()
                    if success:
                        self.completed_subjects.append((subject_id, session))
                    else:
                        self.failed_subjects.append((subject_id, session))
                except Exception as e:
                    self.logger.error(f"Exception processing {subject_id}/{session}: {e}")
                    self.failed_subjects.append((subject_id, session))
    
    def _run_sequential(self, subjects: List[Tuple[str, str]],
                       skip_markers: bool, skip_models: bool, skip_analysis: bool):
        """Run processing sequentially."""
        self.logger.info("Running sequential processing")
        
        for i, (subject_id, session) in enumerate(subjects, 1):
            self.logger.info(f"Progress: {i}/{len(subjects)}")
            success = self.process_subject(subject_id, session, skip_markers, skip_models, skip_analysis)
            
            # Track completed/failed subjects
            if success:
                self.completed_subjects.append((subject_id, session))
            else:
                self.failed_subjects.append((subject_id, session))
    
    def _run_command(self, cmd: List[str]) -> bool:
        """
        Run a command and return success status.
        
        Parameters
        ----------
        cmd : List[str]
            Command to execute
            
        Returns
        -------
        bool
            True if command succeeded, False otherwise
        """
        if self.dry_run:
            self.logger.info(f"DRY RUN: {' '.join(cmd)}")
            return True
            
        try:
            self.logger.debug(f"Running: {' '.join(cmd)}")
            
            # Use Popen with stderr redirected to stdout to avoid deadlock
            process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, 
                                     text=True, universal_newlines=True, bufsize=1)
            
            # Stream output in real-time
            while True:
                output = process.stdout.readline()
                if output == '' and process.poll() is not None:
                    break
                if output:
                    self.logger.info(f">> {output.strip()}")
            
            # Wait for process to complete and get return code
            return_code = process.wait()
            
            if return_code != 0:
                raise subprocess.CalledProcessError(return_code, cmd)
                
            return True
            
        except subprocess.CalledProcessError as e:
            self.logger.error(f"Command failed: {' '.join(cmd)}")
            self.logger.error(f"Exit code: {e.returncode}")
            if e.stdout:
                self.logger.error(f"STDOUT: {e.stdout}")
            if e.stderr:
                self.logger.error(f"STDERR: {e.stderr}")
            return False


def main():
    """Main function for command line usage."""
    parser = argparse.ArgumentParser(
        description="Benchmark Data Analysis Pipeline",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
    python pipeline.py --subject AD023
    python pipeline.py --subjects AD023,YC260,BC031  
    python pipeline.py --all --skip-models
    python pipeline.py --random 5 --batch-size 4
    python pipeline.py --analysis-only --all
        """
    )

    # Set default paths relative to script location
    # Default root is doc_benchmark
    project_root = str(Path(__file__).parent.parent)
    
    # Subject selection (mutually exclusive)
    subject_group = parser.add_mutually_exclusive_group(required=True)
    subject_group.add_argument('--subject', 
                              help='Process single subject')
    subject_group.add_argument('--subjects',
                              help='Process specific subjects (comma-separated)')
    subject_group.add_argument('--all', action='store_true',
                              help='Process all available subjects')
    subject_group.add_argument('--random', type=int, metavar='N',
                              help='Process N random subjects')
    
    # Phase control
    phase_group = parser.add_mutually_exclusive_group()
    phase_group.add_argument('--markers-only', action='store_true',
                            help='Only run markers computation')
    phase_group.add_argument('--analysis-only', action='store_true',
                            help='Only run analysis (markers + individual analysis)')
    phase_group.add_argument('--individual-analysis-only', action='store_true',
                            help='Only run individual analysis (requires existing markers)')
    phase_group.add_argument('--decoder-only', action='store_true',
                            help='Only run decoder analysis')
    phase_group.add_argument('--global-only', action='store_true',
                            help='Only run global analysis')
    phase_group.add_argument('--models-only', action='store_true',
                            help='Only run model training')
    phase_group.add_argument('--statistics-only', action='store_true',
                            help='Only run statistical analysis')
    
    # Individual phase skipping
    parser.add_argument('--skip-markers', action='store_true',
                       help='Skip markers computation phase')
    parser.add_argument('--skip-analysis', action='store_true',
                       help='Skip analysis phase')
    parser.add_argument('--skip-decoder', action='store_true',
                       help='Skip decoder analysis phase')
    parser.add_argument('--skip-global', action='store_true',
                       help='Skip global analysis')
    parser.add_argument('--skip-statistics', action='store_true',
                       help='Skip statistical analysis phase')
    parser.add_argument('--skip-models', action='store_true', 
                       help='Skip model training phase')
    parser.add_argument('--skip-smi', action='store_true',
                       help='Skip SymbolicMutualInformation computation (recommended for large datasets)')
    parser.add_argument('--skip-gfp', action='store_true',
                       help='Skip Global Field Power analysis (speeds up global analysis)')
    parser.add_argument('--force-recompute', action='store_true',
                       help='Force recomputation of already completed subjects')
    parser.add_argument('--aggregate', action='store_true',
                       help='For --decoder-only: aggregate existing results without processing subjects')
    
    # Configuration
    parser.add_argument('--data-dir', 
                        required=True,
                       help='Path to data directory')
    parser.add_argument('--results-dir',
                       default=f'{project_root}/results',
                       help='Path to results directory')
    parser.add_argument('--src-dir',
                       default=f'{project_root}/src',
                       help='Path to source code directory')
    parser.add_argument('--metadata-dir',
                       required=True,
                       help='Path to metadata directory')

    parser.add_argument('--batch-size', type=int, default=4,
                       help='Number of parallel processes (default: 4)')
    
    # Other options
    parser.add_argument('--verbose', '-v', action='store_true',
                       help='Enable verbose output')
    parser.add_argument('--dry-run', action='store_true',
                       help='Show what would be done without executing')
    
    args = parser.parse_args()
    
    # Resolve subject arguments
    subject_args = []
    if args.subject:
        subject_args = [args.subject]
    elif args.subjects:
        subject_args = args.subjects.split(',')
    elif args.all:
        subject_args = ["ALL"]
    elif args.random:
        subject_args = [f"RANDOM:{args.random}"]
    
    # Handle phase-only modes
    skip_markers = (args.skip_markers or args.models_only or args.decoder_only or 
                   args.global_only or args.statistics_only or args.individual_analysis_only)
    skip_models = (args.skip_models or args.markers_only or args.analysis_only or 
                  args.decoder_only or args.global_only or args.statistics_only or 
                  args.individual_analysis_only)
    skip_analysis = (args.skip_analysis or args.markers_only or args.models_only or 
                    args.decoder_only or args.global_only or args.statistics_only)
    skip_decoder = (args.skip_decoder or args.markers_only or args.models_only or 
                   args.analysis_only or args.global_only or args.statistics_only or 
                   args.individual_analysis_only)
    skip_global = (args.skip_global or args.markers_only or args.models_only or 
                  args.analysis_only or args.decoder_only or args.individual_analysis_only)
    skip_statistics = (args.skip_statistics or args.markers_only or args.models_only or 
                      args.analysis_only or args.decoder_only or args.individual_analysis_only)
    
    # Create pipeline
    pipeline = Pipeline(
        data_dir=args.data_dir,
        results_dir=args.results_dir,
        src_dir=args.src_dir,
        metadata_dir=args.metadata_dir,
        batch_size=args.batch_size,
        verbose=args.verbose,
        dry_run=args.dry_run,
        skip_smi=args.skip_smi,
        skip_gfp=args.skip_gfp
    )
    
    # Handle statistics-only mode
    if args.statistics_only:
        pipeline.run_statistical_analysis()
        return
    
    # Handle decoder-only mode
    if args.decoder_only:
        aggregate_only = getattr(args, 'aggregate', False)
        pipeline.run_decoder_phase(force_recompute=args.force_recompute, aggregate_only=aggregate_only)
        return
    
    # Handle global-only mode
    if args.global_only:
        pipeline.run_global_analysis()
        return
    
    # Handle models-only mode  
    if args.models_only:
        pipeline.run_models_phase()
        return

    # Resolve subjects
    subjects = pipeline.resolve_subjects(subject_args, force_recompute=args.force_recompute)
    
    if not subjects:
        print("No subjects to process")
        return
        
    # Run pipeline
    pipeline.run_pipeline(
        subjects=subjects,
        skip_markers=skip_markers,
        skip_models=skip_models, 
        skip_analysis=skip_analysis,
        skip_decoder=skip_decoder,
        skip_global=skip_global,
        skip_statistics=skip_statistics,
        force_recompute=args.force_recompute
    )


if __name__ == "__main__":
    main()
